import skfuzzy.cluster as fuzz
import numpy as np
import pandas as pd

# Importar o conjunto de dados
url1 = "https://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.data"
url2 = "https://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.test"

cols = ["CLASS", "REGION-CENTROID-COL", "REGION-CENTROID-ROW", "REGION-PIXEL-COUNT", "SHORT-LINE-DENSITY-5", "SHORT-LINE-DENSITY-2", "VEDGE-MEAN", "VEDGE-SD", "HEDGE-MEAN", "HEDGE-SD", "INTENSITY-MEAN","RAWRED-MEAN","RAWBLUE-MEAN","RAWGREEN-MEAN","EXRED-MEAN","EXBLUE-MEAN","EXGREEN-MEAN","VALUE-MEAN","SATURATION-MEAN","HUE-MEAN"]

df1 = pd.read_csv(url1, header=2, names=cols)
df2 = pd.read_csv(url2, header=2, names=cols)
df3 = pd.concat([df1, df2]).drop(["REGION-CENTROID-COL", "REGION-CENTROID-ROW", "REGION-PIXEL-COUNT"], axis=1)

#Se tirar essa parte dá erro no índice de Rand para df1
df1 = df3.iloc[:,4:9] #Dataset específico para o código
df2 = df3.iloc[:,10:19]
df3 = df3.iloc[:,4:19]

# Converter os dados para uma matriz NumPy
X = df1.iloc[:, :-1].to_numpy(dtype=np.float32)


# Separar as classes dos dados e normalizá-los/QUANDO NAO NORMALIZO TB DÁ ERRO NO INDICE DE RAND
y = df1.iloc[:, -1].to_numpy()
X = (X - X.mean(axis=0)) / X.std(axis=0)

# Executar o algoritmo FCM com a distância de City-Block e a partição fuzzy em 7 grupos, repetindo-o 50 vezes para obter o melhor resultado
n_clusters = 7
best_obj_func = np.inf
best_U = None # Melhor resultado

# Executando o algoritmo FCM com a distância city-block personalizada
for i in range(50):
    cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=1000, metric='cityblock')
    if jm.mean() < best_obj_func:
        best_obj_func = jm.mean()
        best_U = u

# Imprimindo os rótulos dos clusters e os centros
labels = np.argmax(u, axis=0)
centers = cntr.T
print(labels)
print('------------------------')
print(centers)
print('------------------------')
print(best_U)

#Melhor resultado de acordo com a função objetivo
best_jm = np.inf

cntr, u, _, _, jm, _, _ = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=1000, metric='cityblock')
if jm.mean() < best_jm:
    best_jm = jm.mean()
    best_U = u
print("Melhor resultado de acordo com a Função objetivo:", best_jm)

#Modiffied Partition Coefficient e Partition entropy:
pc = np.sum(np.max(best_U, axis=0)) / X.shape[0]
print("Modified Partition Coefficient:", pc)

pe = - np.sum(best_U * np.log(best_U)) / X.shape[0]
print("Partition Entropy:", pe)

# Fuzzy C-Means para obter a partição CRISP
cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=1000, metric='cityblock')
labels = np.argmax(u, axis=0)

# Índice Rand
from sklearn.metrics import adjusted_rand_score
true_labels = np.array([int(i)-1 for i in y]) # Converter os labels em y
ri = adjusted_rand_score(true_labels, labels)
print("Índice Rand:", ri)

#F-measure adaptada para agrupamento
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(true_labels, labels)

# Calcular precisao, recall, e F-measure para cada cluster
precision = []
recall = []
f_measure = []
for i in range(n_clusters):
    tp = cm[i, i]
    fp = cm[:, i].sum() - tp
    fn = cm[i, :].sum() - tp
    if tp == 0:
        precision.append(0)
        recall.append(0)
        f_measure.append(0)
    else:
        precision.append(tp / (tp + fp))
        recall.append(tp / (tp + fn))
        f_measure.append(2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))

# Calcular o f-measure adaptada para agrupamento
f_measure_group = sum(f_measure) / n_clusters
print("F-measure adaptada para agrupamento:", f_measure_group)

#Comparar os pares na partição

from itertools import combinations

# Compare pairs of partitions
for i, j in combinations(range(7), 2):
    labels1 = (labels == i).astype(int)
    labels2 = (labels == j).astype(int)
    ri = adjusted_rand_score(labels1, labels2)
    
    cm = confusion_matrix(labels1, labels2)
    precision = cm[1, 1] / cm[:, 1].sum()
    recall = cm[1, 1] / cm[1, :].sum()
    if precision == 0 or recall == 0:
        f_measure = 0
    else:
        f_measure = 2 * precision * recall / (precision + recall)
    
    print("Pair ({}, {}) - Rand index: {:.3f}, F-measure adapted to the group: {:.3f}".format(i, j, ri, f_measure))
    
    #Matriz de confusão
    
    from sklearn.metrics import confusion_matrix

# Convert true labels to 0-based labels
true_labels = np.array([int(i)-1 for i in y])

# Compute confusion matrix
cm = confusion_matrix(true_labels, labels)

print("Matriz de confusão:")
print(cm_labeled)
